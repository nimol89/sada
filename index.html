
<!DOCTYPE html>
<html>
<head>
<APM_DO_NOT_TOUCH>

<script type="text/javascript">
(function(){
window.mhu=!!window.mhu;try{(function(){(function(a){var d=this[l("tnemucod")],g=[];try{a={" == f":!a};var h=d.getElementsByTagName("*");for(var k in h)if(a[" == f"])try{h[k].setAttribute("data-safe","true")}catch(m){g.push(m.message)}}catch(m){g.push(m.message)}return g;function l(m){var n="";for(var r in m)n=m[r]+n;return n}})(!0);var b=27;
try{var aa,ea,ma=c(476)?0:1,oa=c(460)?0:1,qa=c(861)?0:1,ra=c(82)?0:1,ua=c(817)?0:1,xa=c(933)?0:1,ya=c(893)?0:1;for(var Ca=(c(491),0);Ca<ea;++Ca)ma+=c(318)?1:2,oa+=(c(103),2),qa+=(c(565),2),ra+=(c(122),2),ua+=c(882)?1:2,xa+=(c(725),2),ya+=c(631)?2:3;aa=ma+oa+qa+ra+ua+xa+ya;window.eb===aa&&(window.eb=++aa)}catch(a){window.eb=aa}var e=!0;function f(a){var d=arguments.length,g=[];for(var h=1;h<d;h++)g[h-1]=arguments[h]-a;return String.fromCharCode.apply(String,g)}
function Da(a){var d=42;a&&(document[q(d,160,147,157,147,140,147,150,147,158,163,125,158,139,158,143)]&&document[q(d,160,147,157,147,140,147,150,147,158,163,125,158,139,158,143)]!==t(68616527624,d)||(e=!1));return e}function t(a,d){a+=d;return a.toString(36)}function q(a){var d=arguments.length,g=[];for(var h=1;h<d;++h)g.push(arguments[h]-a);return String.fromCharCode.apply(String,g)}function Ea(){}Da(window[Ea[t(1086827,b)]]===Ea);Da(typeof ie9rgb4!==t(1242178186172,b));
Da(RegExp("\x3c")[f(b,143,128,142,143)](function(){return"\x3c"})&!RegExp(t(42862,b))[t(1372178,b)](function(){return"'x3'+'d';"}));
var Fa=window[q(b,124,143,143,124,126,131,96,145,128,137,143)]||RegExp(f(b,136,138,125,132,151,124,137,127,141,138,132,127),f(b,132))[t(1372178,b)](window["\x6e\x61vi\x67a\x74\x6f\x72"]["\x75\x73e\x72A\x67\x65\x6et"]),Ga=+new Date+(c(825)?515755:6E5),Ha,Ia,Ka,Ma=window[f(b,142,128,143,111,132,136,128,138,144,143)],Na=Fa?c(204)?15221:3E4:c(857)?6574:6E3;
document[f(b,124,127,127,96,145,128,137,143,103,132,142,143,128,137,128,141)]&&document[q(b,124,127,127,96,145,128,137,143,103,132,142,143,128,137,128,141)](f(b,145,132,142,132,125,132,135,132,143,148,126,131,124,137,130,128),function(a){var d=24;document[f(d,142,129,139,129,122,129,132,129,140,145,107,140,121,140,125)]&&(document[f(d,142,129,139,129,122,129,132,129,140,145,107,140,121,140,125)]===t(1058781959,d)&&a[f(d,129,139,108,138,141,139,140,125,124)]?Ka=!0:document[f(d,142,129,139,129,122,
129,132,129,140,145,107,140,121,140,125)]===f(d,142,129,139,129,122,132,125)&&(Ha=+new Date,Ka=!1,A()))});function A(){if(!document[q(65,178,182,166,179,186,148,166,173,166,164,181,176,179)])return!0;var a=+new Date;if(a>Ga&&(c(901)?759266:6E5)>a-Ha)return Da(!1);var d=Da(Ia&&!Ka&&Ha+Na<a);Ha=a;Ia||(Ia=!0,Ma(function(){Ia=!1},c(79)?0:1));return d}A();var Qa=[c(413)?13058352:17795081,c(28)?27611931586:2147483647,c(272)?1215342056:1558153217];
function Ta(a){var d=56;a=typeof a===t(1743045620,d)?a:a[q(d,172,167,139,172,170,161,166,159)](c(924)?53:36);var g=window[a];if(!g||!g[f(d,172,167,139,172,170,161,166,159)])return;var h=""+g;window[a]=function(k,l){Ia=!1;return g(k,l)};window[a][q(d,172,167,139,172,170,161,166,159)]=function(){return h}}for(var Xa=(c(827),0);Xa<Qa[q(b,135,128,137,130,143,131)];++Xa)Ta(Qa[Xa]);Da(!1!==window[t(29127,b)]);window.Ra=window.Ra||{};window.Ra.mc="0853efae4619400049f1269e0fdd189bfec7f67b539539569963c610056248285aa680ff456e0c62522b6371d4c0490a6fe929ab65182e9ddaa5e1b1b216ac95b8d20f803019e676";
function B(a){var d=+new Date;if(!document[f(97,210,214,198,211,218,180,198,205,198,196,213,208,211,162,205,205)]||d>Ga&&(c(241)?357910:6E5)>d-Ha)var g=Da(!1);else g=Da(Ia&&!Ka&&Ha+Na<d),Ha=d,Ia||(Ia=!0,Ma(function(){Ia=!1},c(892)?0:1));return!(arguments[a]^g)}function c(a){return 33>a}
(function(){var a=/(A([0-9a-f]{1,4}:){1,6}(:[0-9a-f]{1,4}){1,1}Z)|(A(([0-9a-f]{1,4}:){1,7}|:):Z)|(A:(:[0-9a-f]{1,4}){1,7}Z)/ig,d=document.getElementsByTagName("head")[0],g=[];for(d&&(d=d.innerHTML.slice(0,1E3));d=null!==a.exec("");)g.push(d)})();})();}catch(x){}finally{ie9rgb4=void(0);};function ie9rgb4(a,b){return a>>b>>0};

})();

</script>
</APM_DO_NOT_TOUCH>

<script type="text/javascript" src="/TSPD/082149a1b4ab20005ccc05f6b0d2e1dd7fd7c0def21340628796a359b5c9878acef042ce34e5ccab?type=9"></script>

  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="We uncover a vulnerability in LoRA fine-tuned models wherein an attacker is able to undo the fine-tuning process and recover the weights of the original pre-trained model.">
  <meta property="og:title" content="Recovering the Pre-Fine-Tuning Weights of Generative Models"/>
  <meta property="og:description" content="We uncover a vulnerability in LoRA fine-tuned models wherein an attacker is able to undo the fine-tuning process and recover the weights of the original pre-trained model."/>
  <meta property="og:url" content="https://vision.huji.ac.il/spectral_detuning/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/og_banner.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Recovering the Pre-Fine-Tuning Weights of Generative Models">
  <meta name="twitter:description" content="We uncover a vulnerability in LoRA fine-tuned models wherein an attacker is able to undo the fine-tuning process and recover the weights of the original pre-trained model.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/twitter_banner.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="LLMs, Model Alignment, Stable Diffusion, Pre-Fine-Tuning, Spectral DeTuning, Mistral, LLaMA, jailbreaking, safety training, fine-tuning">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Spectral DeTuning</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" sizes="180x180" href="static/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="static/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="static/images/favicon-16x16.png">
  <link rel="manifest" href="static/images/site.webmanifest">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet">
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Recovering the Pre-Fine-Tuning Weights of Generative Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://pages.cs.huji.ac.il/eliahu-horwitz/" target="_blank">Eliahu Horwitz</a>,</span>
                <span class="author-block">
                  <a href="https://pages.cs.huji.ac.il/jonkahana/" target="_blank">Jonathan Kahana</a>,</span>
                  <span class="author-block">
                    <a href="https://www.cs.huji.ac.il/w~ydidh/" target="_blank">Yedid Hoshen</a>
                  </span>
                </div>

                <div class="is-size-5 publication-authors">
                  <span class="author-block">The Hebrew University of Jerusalem<br>ICML 2024<br></span>
                </div>

                <div class="column has-text-centered">
                  <div class="publication-links">
                   <!-- Arxiv PDF link -->
                   <span class="link-block">
                    <a href="https://arxiv.org/pdf/2402.10208.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/eliahuhorwitz/Spectral-DeTuning" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2402.10208" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>

                <!-- Dataset -->


                  <span class="link-block">
                      <a href="https://huggingface.co/datasets/Eliahu/LoWRA-Bench" target="_blank"
                          class="external-link button is-normal is-rounded is-dark">
                          <span class="icon" style="vertical-align: middle; font-size: 20px;">&#129303;</span>
                          <span style="vertical-align: middle;">Dataset</span>
                      </a>
                  </span>    
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="90%">
        <!-- Your video here -->
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        We uncover a vulnerability in LoRA fine-tuned models wherein an attacker is able to undo the fine-tuning process and recover the weights of the original pre-trained model. 
        Our method, <em>Spectral DeTuning</em>, can perform the attack in an unsupervised and data-free manner on real models such as Stable Diffusion and Mistral. 
        For simplicity, we illustrate the attack on a single layer, in reality, the attack is carried out independently on all the fine-tuned layers.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p> The dominant paradigm in generative modeling consists of two steps: i) pre-training on a large-scale but unsafe dataset, ii) aligning the pre-trained model with human values via fine-tuning. This practice is considered safe, as no current method can recover the unsafe, <em>pre-fine-tuning</em> model weights. In this paper, we demonstrate that this assumption is often false. Concretely, we present <em>Spectral DeTuning</em>, a method that can recover the weights of the pre-fine-tuning model using a few low-rank (LoRA) fine-tuned models. In contrast to previous attacks that attempt to recover pre-fine-tuning capabilities, our method aims to recover the exact pre-fine-tuning weights. Our approach exploits this new vulnerability against large-scale models such as a personalized Stable Diffusion and an aligned Mistral.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <div class="level-set has-text-justified">
            <p>
             In this paper, we identify a vulnerability in fine-tuned models, wherein the pre-fine-tuning (Pre-FT) weights, i.e., the model weights before the fine-tuning stage, can be recovered using a small number of models fine-tuned via low-rank adaptation (LoRA).
             Generative modeling consists of two steps:
             <ol>
              <li>Pre-training on unsafe data.</li>
              <li>Alignment and safety fine-tuning.</li>
            </ol>
            Recovering the original pre-fine-tuning unsafe weights, is implicitly assumed to be impossible. We demonstrate that this safety assumption is often false.
          </p>
        </div>
<img src="static/images/mistral.png" alt="Recovering the Pre-Fine-Tuning Weight of an Aligned Mistral 7B" class="blend-img-background center-image"/>
        </div>
        
      </div>
    </div>
  </div>
</div>
</section>


<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container  is-max-desktop">
      <h2 class="title is-3">Pre-Fine-Tuning Weight Recovery</h2>
      <div class="level-set has-text-justified">
        <p>
          We propose the task of <it>Pre-Fine-Tuning Weight Recovery</it>. In this paper, we tackle this task in cases where multiple LoRA fine-tuned flavors of the same source model are available.
          To solve this task we present <em>Spectral DeTuning</em>, a method that recovers Pre-FT weights of SoTA models using iterative low-rank matrix factorization
          </p>
       <p>
        Unlike previous attacks on model alignment that attempt to recover Pre-FT capabilities, we aim to recover the exact Pre-FT weights.<br>
        Moreover, it does not require running inference through the model. This is advantageous as i) it does not require training data ii) it is highly parallelizable, e.g., on a cluster of desktop GPUs such as RTX2080 our method can recover the Pre-FT weights of a Mistral-7B model in under five minutes.
       </p>
     </div>
     <img src="static/images/stable_diffusion.png" alt="Recovering the Pre-Fine-Tuning Weight of an Aligned Mistral 7B" class="blend-img-background center-image"/>
          <p><strong>Stable Diffusion Results:</strong> Spectral DeTuning recovers the Pre-Fine-Tuning images with high precision, even when using "in the wild" LoRAs, essentially reversing the personalization fine-tuning of the LoRA model.
      </div>
   </div>
 </div>
</section>



<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">Vulnerability of SoTA Models</h2>
          <div class="level-set has-text-justified">
            <p>
              By using just 5 LoRAs taken from CivitAI, we can recover the Pre-FT Stable Diffusion weights with a vanishingly small error. As can be seen below, scaling up to a DPO aligned Mistral only requires 8 LoRAs.
            </p>
            <img src="static/images/semantic_conv.png" alt="Number of LoRAs for semantic convergence" class="center-image"/>
            <div class="container mt-4">
              <div class="alert alert-danger" role="alert">
                <strong>Implications:</strong> SoTA LLMs that use LoRA for alignment fine-tuning are vulnerable to Pre-FT weight recovery attacks
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>


<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container  is-max-desktop">
      <h2 class="title is-3">Spectral DeTuning</h2>
      <div class="level-set has-text-justified">
        <p>
          The core idea of Spectral DeTuning is to iteratively break down the optimization into a set of simple sub-problems which have closed-form solutions. This results in a simple yet powerful algorithm that can be implemented in 8 lines of code.
       </p>
       <img src="static/images/algorithm.png" alt="Spectral DeTuning code" class="center-image"/>
     </div>
   </div>
 </div>
</section>

<section class="section hero is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <div class="content">
          <h2 class="title is-3">LoWRA Bench</h2>
          <div class="level-set has-text-justified">
            <p>
              To stimulate research into preventing Pre-FT weight leakage and the associated risks in terms of model safety and alignment we present <strong>Lo</strong>RA <strong>W</strong>eight <strong>R</strong>ecovery <strong>A</strong>ttack (LoWRA) Bench, a comprehensive benchmark designed to evaluate Pre-FT weight recovery methods.<br>

              Our dataset encompasses three pre-trained representative source models: a Vision Transformer (ViT) trained on ImageNet-1K, Stable Diffusion 1.5, and Mistral-7B-v0.1. Notably, these models are widely used and deployed in numerous production systems.

            </p>
            <img src="static/images/lowra_bench.png" alt="LoWRA Bench Details" class="center-image"/>
          </div>
        </div>
      </div>
    </div>
  </section>


<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container  is-max-desktop">
      <h2 class="title is-3">Broader Impact</h2>
      <div class="level-set has-text-justified">
        <p>
          This work uncovers a significant vulnerability in fine-tuned models, allowing attackers to access pre-fine-tuning weights. While this discovery reveals potential security risks, our primary objective is to advance the field of Machine Learning and raise awareness within the research community about the existing vulnerabilities in current models.
        </p>
        <p>
          Instead of using the findings of this study to execute attacks, we advocate for their use by model creators to enhance the safety and security of their models. By acknowledging and addressing vulnerabilities, creators can proactively safeguard against potential threats.
        </p>
        <p>
          Furthermore, in the discussion section, we outline potential future directions and mitigation strategies. Following established practices in the cyber security community, we emphasize the importance of open discussion and encourage the reporting of vulnerabilities. By fostering transparency and collaboration, we can collectively create a safer environment for deploying machine learning models.
       </p>
     </div>
   </div>
 </div>
</section>



<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{horwitz2024recovering,
  title={Recovering the Pre-Fine-Tuning Weights of Generative Models},
  author={Horwitz, Eliahu and Kahana, Jonathan and Hoshen, Yedid},
  journal={arXiv preprint arXiv:2402.10208},
  year={2024}
}</code></pre>
  </div>
</section>
<!--End BibTex citation -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theֲ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>ֲ project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->

<!-- Default Statcounter code for Spectral DeTuning
https://vision.huji.ac.il/spectral_detuning/ -->
<script type="text/javascript">
var sc_project=12968013; 
var sc_invisible=1; 
var sc_security="c534194a"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics
Made Easy - Statcounter" href="https://statcounter.com/"
target="_blank"><img class="statcounter"
src="https://c.statcounter.com/12968013/0/c534194a/1/"
alt="Web Analytics Made Easy - Statcounter"
referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->

</body>
</html>
